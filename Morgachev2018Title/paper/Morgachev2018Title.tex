\documentclass[12pt,twoside]{article}

\newcommand{\fixme}[1]{\textcolor{red}{#1}}

    \usepackage{jmlda}
    \usepackage{graphics}
    \usepackage{booktabs}
    \usepackage{wrapfig}
    \usepackage{multirow}
    \usepackage{enumitem}
    \usepackage{hyperref}
    % \usepackage{DejaVuSans}
    
    \graphicspath{{images/}}
    % \setcounter{secnumdepth}{3}
    
\renewcommand{\baselinestretch}{1.34}
    %\NOREVIEWERNOTES
    \title
        {Динамическое выравнивание многомерных временных рядов}
    \author
        {Гончаров~А.\,В., Моргачев~Г.\,И., Смирнов~В.\,, Липницкая~Т.\,} % основной список авторов, выводимый в оглавление
    \thanks{
        Работа выполнена при финансовой поддержке РФФИ, проект \No\,00-00-00000.
        Научный руководитель:  Гончаров~А.\,В.
        Задачу поставил:  Гончаров~А.\,В.
        Консультант:  Гончаров~А.\,В.
    }
    \email
        {morgachev.gi@phystech.edu, smirnov.vs@phystech.edu, tanya.lipnizky@yandex.ru}
    \organization
        {МФТИ}

    \abstract{
        В работе решается задача выбора оптимальной функции расстояния между двумя наборами временных рядов с общей осью времени. Метод динамического выравнивания одномерных временных рядов использует в качестве функции расстояния стоимость выравнивающего пути. Данный путь получается в результате динамического выравнивания временных осей друг относительно друга.
        Определенная таким образом функция расстояния называется \textit{функцией стоимости} выравнивания наборов рядов.
        Предлагается обобщение алгоритма выравнивания на случай наборов, состоящих более чем из одного ряда.
        
        В работе сравниваются функции стоимости, полученные на основе выбора различных функций расстояния между значениями наборов. Анализ полученных функций стоимости проведен на примере решения задач метрической кластеризации и метрического поиска эталонной подпоследовательности для многомерных наборов рядов.
        Работа также предлагает модификацию оптимизированного алгоритма вычисления функции стоимости выравнивания рядов, позволяющую проводить её вычисления для наборов.
        Результаты моделирования представлены на основе размеченных данных о деятельности человека, полученных с носимого устройства, а также данных о движении руки в процессе написания текста, полученных с графического планшета.
        
        Обоснованность метрического подхода к решению задачи демонстрируется путем сравнения с результатами на основе авторегрессионной модели.

        \bigskip
        \textbf{Ключевые слова}: \emph {временные ряды, многомерные временные ряды, DTW}.
    }

        
    \begin{document}
    \renewcommand{\baselinestretch}{1.34}
    \maketitle
    \setcounter{secnumdepth}{3}
    \section{Введение}\label{intro}
        
        Для вычисления функции расстояния между временными рядами применяются различные подходы, одним из которых является поточечный подход: определение расстояния между как суммы расстояний между соответственными точками рядов, слабо отражает сходства объектов в связи с возможными деформациями оси времени: сдвигами и растяжениями~\cite{01f4ab11a9ff49ff909094a135dcfe33}.
        Одним из способов решения этой проблемы является выравнивание временных рядов (Dynamic Time Warping)~\cite{Keogh:1999:SUD:645803.669511} и его модификации~\cite{journals/ida/SalvadorC07,Keogh01derivativedynamic}.
        Данный способ позволяет найти оптимальный выравнивающий путь между рядами, деформированными во времени~\cite{salvador2004fastdtw}. Стоимость выравнивающего пути используется в качестве расстояния между выравниваемыми объектами. Заданная таким образом функция расстояния для однозначности обозначений называется \textit{функцией стоимостью} выравнивания рядов.
        
        Данные, имеющие более одного измерения в каждый момент времени представляются в виде \textit{наборов временных рядов} с общей осью времени. Набор временных рядов будет обозначаться $X = \{X^1,\dots X^l\}$, каждый $X^i \in \mathbb{R}^{n}$ \--- временной ряд длинны $n$. Набор временных рядов далее для краткости называется рядом и рассматриваться как вектор-функция от дискретного аргумента~--- времени. Значение этой функции в момент времени~$t$ обозначается~$\mathbf{X}_t$ и называется значением ряда.
        
        Модификации алгоритма выравнивания для случая наборов описано в \cite{Holt2007,Sanguansat2012MultipleMS}.
        В работе \cite{Holt2007} предлагается способ выравнивания наборов рядов, основанный на нормализации исходных данных и нахождении векторной нормы.
        \fixme{???не надо-->} В \cite{Sanguansat2012MultipleMS} упоминается алгоритм, выполняющий выравнивание соответствующих каналов наборов временных рядов независимо друг от друга, однако такой подход не учитывает исходную природу измерений, так как в выравненных рядах одному моменту времени могут соответствовать не одновременных измерения по различным каналам. \fixme{<--???}
        
        \begin{figure}[h!]
            \centering
            {
              \fontsize{11pt}{1pt}\selectfont
               \def\svgwidth{0.95\textwidth}
               \input{images/example.pdf_tex}
            }
            \caption{Иллюстрация выравнивания}\label{example}
        \end{figure}
        
        При выравнивании рядов~\cite{Sanguansat2012MultipleMS} вычисляются расстояния между значениями рядов. \textit{Значением ряда} в момент $t$ обозначим $\mathbf{X}_t = [X^1_t,\dots X^l_t]$, где $X^i_t$ \--- измерение $i$\--го временного ряда в момент времени $t$. Таким образом, значение $\mathbf{X}_t$ в момент $t$ принадлежит пространству $\mathbb{R}^{l}$.  На рис.~\ref{example} синей линией обозначено значение набора из двух временных рядов при $t=18$.
        
        При выравнивании двух рядов относительно общей временной оси, вычисляются расстояния между соответственными значениями. При этом получаемая функция стоимости будет зависеть от выбора функции расстояния между значениями рядов. На рис.~\ref{example} стрелками соединены сравниваемые значения, которые совпадут после выравнивания.

        В этой работе решается задача выбора оптимальной функции стоимости выравнивания наборов временных рядов с общей осью времени. Сравниваются функции расстояния, порожденные $L_1$, $L_2$ нормами, а также косинусное расстояние.
        
        Качество полученных функций стоимости анализируется в двух задачах, решаемых метрическим методом:
        \begin{enumerate}[label=\arabic*)]
            \item Поиск шаблонов в наборе временных рядов
            \item Кластеризация наборов временных рядов
        \end{enumerate}
        Для каждой их которых введены свои метрики качества $Q_\text{поиска}, Q_\text{класт.}$,  соответственно.
        Задача поиска паттернов ставится как нахождение наиболее близкого участка ряда к заданному паттерну. Задача кластеризации ставится как метрическая иерархическая кластеризация.
        
        В ходе эксперимента, предложенный подход был продемонстрирован на задачах поиска приступов эпилепсии~\cite{epi} и распознавания рукописных букв~\cite{characters} для поиска паттернов, а также класстеризации измерений акселерометра телефона в кармане человека при различных видах деятельности~\cite{Kwapisz:2011:ARU:1964897.1964918}. Полученные результаты были сравнены с результатами, полученными на основе использования коэффициентов регрессионных моделей в качестве признаков, описывающих ряд. \fixme{<--???}
    
    \section{Постановка задачи выбора функции стоимости}\label{sec:problem}
    	
	   \textit{Набором временных рядов} называется множество $\{X^1,\dots X^l\}$, где каждый $X^i \in \mathbb{R}^{n}$ \--- временной ряд длинны $n$.
	     
	   \textit{Значением набора} из $l$ временных рядов называется вектор $\mathbf{X}_t = [X^1_t,\dots X^l_t] \in \mathbb{R}^l$, в котором каждому из элементов соответствует значение соответствующего временного ряда в момент времени $t$, как показано на рис.~\ref{example}.
	    
	    Изучается влияния выбора функции расстояния между значениями наборов временных рядов на результат работы DTW на примере двух задач:
        \begin{enumerate}[label=\arabic*)]
            \item Поиск шаблонов в наборе временных рядов
            \item Кластеризация наборов временных рядов
        \end{enumerate} 
        Для каждой их которых введены метрики качества $Q_\text{поиска}, Q_\text{класт.}$,  соответственно.
	  
	  
        % Задано множество $\mathfrak{R}$ функций расстояния между значениями рядов:
        %     $$\mathfrak{R} = \{\rho: \mathbb{R}^l \times \mathbb{R}^l \rightarrow \mathbb{R}_+ \}$$

        % Каждой функции расстояния $\rho$ между векторами соответствует функция стоимости оптимального выравнивающего пути. Множество таких функций расстояния между наборами временных рядов из множества $\mathfrak{X}$: 
        % $$\text{DTW}_{\rho}: \mathfrak{X} \times \mathfrak{X} \rightarrow \mathbb{R}_+.$$
        
        Рассматриваются следующие функций расстояния между векторами $\mathbf{X}_t, \mathbf{Y}_\tau$:         
        \begin{enumerate}[label=\arabic*)]
            \item $\rho_{L_1}(\mathbf{X}_t, \mathbf{Y}_\tau) = \|\mathbf{X}_t - \mathbf{Y}_\tau \|_1$;
            \item $\rho_{L_2}(\mathbf{X}_t, \mathbf{Y}_\tau) = \|\mathbf{X}_t - \mathbf{Y}_\tau \|_2$;
            \item $\rho_\text{cosine}(\mathbf{X}_t, \mathbf{Y}_\tau) = 1 - \dfrac{\mathbf{X}^T_t \mathbf{Y}_\tau}{\|\mathbf{X}_t\|_2 \|\mathbf{Y}_\tau\|)2}$.
        \end{enumerate}
        
        Решается задача выбора оптимальной функции расстояния  между значениями рядов относительно внешних критериев качества $Q_\text{поиска}, Q_\text{класт.}$.
        $$
            \rho_i^* = \argmax_\rho Q_i(\rho).
        $$
    
        
        Сравнивается качество и скорость работы предложенного подхода с другими используемыми методами:
        \begin{enumerate}[label=\arabic*)]
            \item определение функции расстояния на основе поточечных расстояний между рядами, при равным длинах рядов:
                $$
                    ED(X, Y) = \sum\limits_{i=1}^T \|X_t - Y_t\|_2,
                $$

            \item применение авторегрессионной модели для описания ряда:
            $$
                \mathbf{X}_T =  \mathbf{c} + \sum\limits_{i=0}^{T - 1} a_i\mathbf{X}_{T-i} + \epsilon_T.
            $$
        \end{enumerate}
    
    \label{sec:dtw}\section{Алгоритм динамического выравнивания DTW}

        В качестве метрического расстояния между наборами используется стоимость \textit{пути наименьшей стоимости}. \\
        Задано два набора временных рядов, $X, Y$ длины $n$.
        Для вычисления пути требуется построить матрицу размера $n\times n$ c элементами $D_{ij}=\rho(X_i, Y_j)$, где $\rho$ \--- выбранная функция расстояния, $X_i, Y_j$ \--- значения рядов. Между наборами рядов строится \textit{выравнивающий путь} $W$, который минимизирует расстояние между ними.
        
        \begin{Def}{}
             Путь $W = [w_1,\dots, w_K]$ представляет собой упорядоченное множество пар индексов элементов матрицы $D$, $w_m = (i, j)_m$, при этом $K$ \--- длина пути. Кроме того, путь должен удовлетворять следующим условиям.
                \begin{itemize}
                    \item[$\bullet$] Граничные условия: $w_1=(1,1)$, $w_K=(n, n)$.
                    \item[$\bullet$] Непрерывность: $w_k = (i, j)$, $w_{k-1}=(i', j')$ : $i-i' \leq 1$, $j-j' \leq 1$. Это ограничение означает, что в пути могут участвовать только соседние элемента матрицы.
                    \item[$\bullet$] Монотонность: $w_k = (i, j)$, $w_{k-1}=(i', j')$ : $i-i' \geq 0$, $j-j'\geq 0$. Это ограничение гарантирует, что путь не возвращается к пройденному значению.
                \end{itemize}
        \end{Def}
        
        \begin{Def}
            Стоимостью пути $W$ называется сумма всех соответствующих элементов матрицы:
            $$\text{cost}(X, Y, W) = \sum\limits_{(i, j)\in W} D_{ij}.$$
        \end{Def}
        \begin{Def}
            Оптимальным выравнивающим путем между наборами временных рядов $X, Y$ называется путь минимальной стоимости. $$\text{DTW}(X, Y) = W^* = \argmin\limits_{W}\text{cost}(W)$$
        \end{Def}

        Построение оптимального выравнивающего пути методом DTW проводится с помощью рекуррентной процедуры:
        $$\gamma_{1j} = D_{1j},\ \ \gamma_{i1} = D_{i1};$$
        $$\gamma(i, j) = D_{ij} + \min({\gamma(i-1, j-1), \gamma(i-1, j), \gamma(i, j-1)}).$$
        Здесь $\gamma(i, j)$ суммарное расстояние, $D_{ij}$ \--- расстояние в текущей клетке. Элемент $\gamma_{ij}$ заданной таким образом матрицы $\gamma$ равен стоимости выравнивающего пути между первыми $i$ и $j$ значениями $X$ и $Y$ соответственно.

        
        Дополнительным ограничением, позволяющим значительно ускорить вычисление пути, является использование полосы Сако~--Чиба, ограничивающей максимально возможное отклонение от диагонали матрицы $D$.
                
    \label{sec:search}\section{Задача поиска паттернов}
        
        Рассматривается задача поиска заданного паттерна в наборах временных рядов.
        Имеется набор временных рядов $X$ длинны $n$, содержащий сегменты класса $\mathfrak{P}$.
        Класс $\mathfrak{P}$ \--- в нашем случае, набор временных рядов длины $m \ll n$. \\
        \begin{Def}{}
            Под паттерном класса $\mathfrak{P}$ будет подразумевать матожидание ряда из данного класса.
        \end{Def}
        
        Известно $k$ представителей класса $\mathfrak{P}$, \textit{не содержащихся в $X$}. \\
        Необходимо найти участки $S$, соответствующие данному классу. \\
        Обозначим множество начал таких участков как $\mathfrak{T} = \{t_1, \dots, t_j \}$.

        Будем считать участок найденным, если его пересечение с предполагаемым участком более $80\%$ длины $m$.
        Поиск будет проводиться путем нахождения расстояния с помощью $DTW_{\rho}$ между фрагментами набора рядов $X$ и шаблоном, полученным из известных экземпляров класса. 

        Рассматриваемая функция качества:
        \begin{align*}
            Q_{\text{поиска}}(DTW_{\rho}) = \dfrac{\sum\limits_{i=1}^j [t_i \--- \text{найден}]}{j}.
        \end{align*}
        
        В ходе эксперимента производилось определение паттернов классов двумя разными способами: путем покомпонентного усреднения известных представителей класса, а также с использованием алгоритма усреднения DBA~\cite{Petitjean2011-DBA}, в процессе которого также производилось выравнивание временных осей наборов рядов из класса. 

    \label{sec:clust}\section{Задача кластеризации}
        Исходные данные представляют собой наборы временных рядов длины $n$.
        Имеется выборка $ \mathfrak{X}$ из $N$ элементов.
        Для каждого элемента выборки $X$ известна метка класса $y \in \mathfrak{Y}$, где $\mathfrak{Y}$ \--- множество меток классов.

        Определим матрицу попарных расстояния:
        $$D(\text{DTW}_\rho(\mathfrak{X})) = ||D_{ij}||, \ \ D_{ij} = \text{DTW}_\rho(X, Z),\ \ X, Z \in \mathfrak{X}.$$
        И модель кластеризации:
        $$
            f: D \rightarrow \mathfrak{S}^N
        $$

        Где $\mathfrak{S}$ \--- множество меток кластеров.
        Будем рассматривать следующие функции качества:
        \begin{align*}
            Q_{\text{поиска} 1}(f(D), \mathfrak{X}) &= \frac{1}{|S|}\sum\limits_{s \in \mathfrak{S}} \max_y \frac{N_s^y}{N_s}  \\
            Q_{\text{поиска} 2}(f(D), \mathfrak{X}) &= \frac{1}{|\mathfrak{S}|}\sum\limits_{s \in \mathfrak{S}} \max_y \frac{(N_s^y)^2}{N_s N^y}
            % Q(f(D), S) = \frac{\sum\limits_{s_i, s_j \in S} \mathbb{I}(z_i = z_j \land  y_i = y_j)}{N^2}            
        \end{align*}
        Здесь: 
        \begin{itemize}[label=$\bullet$]
            \item $N_s$ \--- количество элементов в кластере с меткой $s$. 
            \item $N^y$ \--- количество элементов в классе $y$.
            \item $N_s^y$ \--- количество элементов класса $y$ в классе $s$.
        \end{itemize}


	\paragraph{Описание алгоритма кластеризации}      
        В качестве алгоритма кластеризации используется иерархическая кластеризация, которая базируется на последовательном слияние ближайших кластеров.
        Рассматриваются различные функции расстояния между кластерами: 
        \begin{enumerate}
            \item \textit{complete:}  $d(A, B) = \max\limits_{a \in A, b \in B}(dist(a, b))$ 
            \item \textit{weighted:}  $d(A,B) = \dfrac{(dist(S,B) + dist(T,B))}{2}$, где кластер $A = S \cup T$
            \item \textit{average:}   $d(A,B) = \sum\limits_{a \in A, b \in B} \dfrac{d(a, b)}{(|A|*|B|)}$ 
        \end{enumerate} 
                
    % TODO: formal check it
    \section{Оптимизации}
        \fixme{\Large{Раздел в разработке}\\}
        В основу реализации легла работа \cite{Rakthanmanon:2012:SMT:2339530.2339576}, в которой было использовано большое количество оптимизаций, позволяющих как сократить время вычисления расстояния между рядами, так и, при возможности, вообще не вычислять его. В ходе работы была произведена попытка обобщить данные оптимизации на случай наборов рядов. Ниже приведено их краткое описание. 

        \paragraph{Использование квадрата расстояния}	
        В DTW вычисляется производится вычисление квадратного корня, однако, если упустить этот шаг, относительное расстояние не изменится, поскольку обе функции монотонны и вогнуты. Это упрощает вычисления и позволяет сделать модель легкой для понимания. Таким образом, говоря о DTW, мы подразумеваем квадратные аналоги.
        
        \paragraph{Использование нижней границы}
        Для ускорения поиска паттернов с использованием DTW используется оценка снизу на стоимость выравнивающего пути.
        Данный прием позволяет отбрасывать неподходящие последовательности без дорогостоящего вычисления выравнивающего пути. 
        

        В эксперименте используется каскадная нижняя граница.
        Вначале последовательность проходит проверку на требования $LB_{Kim}$~\cite{lbkim}, которая использует расстояние между максимальными и минимальными длинами значений наборов рядов. 
        
        Однако, для того чтобы сравнить последовательности, они должны быть нормализованы, поэтому значения двух расстояний между максимальными и минимальными точками могут быть ничтожно малы.
        В случае если последовательность удовлетворила требованиям $LB_{Kim}$, происходит вторичная проверка $LB_{Keogh}$, использующей ED.
        
        Также бывает полезным менять роли сравниваемых последовательностей для $LB_{Keogh}$, от этого будет меняться решение к какой последовательности применяется нижняя граница, причем результаты вычисления этих границ для каждой из последовательностей при их сравнении в общем случае не будут равны. Однако данный метод применяется опционально и только в том случае, если другие нижние границы не проявили себя.
        
        \paragraph{Использование верхней границы}
        При вычислении $LB_{Keogh}$, мы можем заметить, что текущая сумма расстояний между каждой парой значений превысила определённое (наибольшее возможное) значение, в таком случае мы можем прекратить подсчёт, так как дальнейший действия дадут ещё более высокий результат.
        
        Если вся $LB_{Keogh}$ была посчитана и мы обнаружили, что должны вычислить DTW полностью, есть способ отбросить лишние вычислительные затраты на стадии подсчёта DTW.
        Если постепенно вычислять DTW слева направо от 1 до k и суммировать частичное накопление DTW с вкладом от $LB_{Keogh}$ от $k + 1$ до $n$. 
        Сумма $DTW(S_{1:k}^i, S_{1:k}^j) + LB_{Keogh}(S_{k+1:n}^i, S_{k+1:n}^j)$ является нижней границей для $DTW(S_{1:n}^i, S_{1:n}^j)$.
        Если в какой-то момент такая нижняя граница превысит верхнюю, расчёт прекращается. Кроме того, расходы на расчёт такой границы незначительны.
        
        Во многих случаях становится полезным изменить порядок поиска верхней границы. Очевидно, что разный порядок поиска приносит разное ускорение, более того существует n! вариантов упорядочивания.
        Для нахождения оптимального варианта, предлагается сортировать индексы основываясь на абсолютных значениях $Z$\--нормализованных наборов рядов.
	
						
    \section{Эксперимент}

        \paragraph{Нахождение подпоследовательностей}
        Использовалось две выборки, первая из которых состояла из временных рядов длиной в 182 значения с тремя каналами, соответсвующих координатам $X, Y$ и силе нажатия на экран планшета.
        Вторая выборка состояла из временных рядов активности мозга в разных состояниях: эпилепсия, ходьба, бег, просмотр картинок и имеет длину элемента в 206 значений.
        Второй датасет имел многократно меньший размер, но при этом значительно отличался от первого: периоды повторения паттернов значительно меньше.

        В обеих выборках из каждого класса выбиралось случайное подмножество представителей, из которых, путем усреднения методами $DBA$ и простым средним, получались поисковые шаблоны. 
        Путем склейки оставшихся рядов в случайном порядке, создавался длинный ряд, в котором производился поиск $k$ наиболее близких фрагментов  для каждого из шаблонов с использованием $ED$ и $DTW_\rho$ с различными $\rho$ в качестве функций расстояния.
            
        Для оценки погрешностей измерений, описанная процедура была проведена с большим количество (20) выборок, полученными из исходной с помощью бутстрепа.    
    
        \begin{table}[h]
            \centering
            \begin{tabular}{c|c *{2}{|*{3}{c}}}  
                \toprule
                  \multirow{2}{*}{$\rho$}& \multirow{2}{*}{average} & 
                            \multicolumn{3}{c|}{characters} & \multicolumn{3}{c}{epi} \\
                \cmidrule(r){3-8}
                                   &  & $Q$ & $t$ & $t_{\text{no optim}}$ & $Q$ & $t$ & $t_{\text{no optim}}$ \\
                \midrule
            \multirow{2}{*}{$L_1$} 
                    & DBA    & $0.83\pm 0.14$ & $2.85\pm 0.43$ & $11\pm 1$ & $0.53\pm 0.10$ & $26\pm 1$ & $25\pm 1$ \\
                    & mean   & $0.87\pm 0.12$ & $2.77\pm 0.45$ & $14\pm 1$ & $0.49\pm 0.08$ & $26\pm 1$ & $28\pm 2$\\
                    
            \midrule\multirow{2}{*}{$L_2$} 
                    & DBA    & $0.80\pm 0.17$ & $2.24\pm 0.30$ & $13\pm 1$ & $0.55\pm 0.07$ & $23\pm 1$ & $26\pm 2$ \\
                    & mean   & $0.84\pm 0.13$ & $2.17\pm 0.22$ & $10\pm 1$ & $0.48\pm 0.10$ & $23\pm 1$ & $26\pm 2$ \\
                    
            \midrule\multirow{2}{*}{$\text{cosine\_dist}$} 
                    & DBA    & $0.77\pm 0.18$ & $3.42\pm 1.00$ & $16\pm 1$ & $0.35\pm 0.10$ & $29\pm 2$ & $38\pm 2$ \\
                    & mean   & $0.81\pm 0.15$ & $3.43\pm 0.83$ & $14\pm 1$ & $0.27\pm 0.06$ & $26\pm 2$ & $38\pm 1$ \\
            \midrule     
            \multirow{2}{*}{ED}
                    & DBA    &   0.08   &   17.511   &    17.511   &    0.172  &   1.620   &    1.620   \\
                    & mean   &   0.09   &   17.645   &    17.645   &    0.172  &   1.540   &    1.540    \\
            \bottomrule
            \end{tabular}
            \caption{Поиск паттернов.}
        \end{table}

        Можно заметить, что на всех данных использование $L_1$ метрики дало лучшие результаты в данной задаче.
        При этом оптимизации позволили сократить время работы в более чем 5 раз на большом датасете (цифры),
            но незначительно в малом, при этом сохранив результаты.

        
        \paragraph{Кластеризация}
        В ходе эксперимента были использованы данные акселерометра мобильного телефона.
        Они представляли собой временные ряды длинной в 600 значений ускорений по осям $X, Y, Z$.
        Из них методом бутстрепа были сгенерированы 20 выборок из 600 рядов по 50 значений в каждом. 
        Каждых из рядов принадлежал к одному из четырёх возможных классов. Данные были равномерно распределены по всем классам.

        Для $DTW$, $ED$ вычислялись матрицы попарных расстояний между парами рядов, на основе которых проводилась кластеризация описанными выше методами.
        В качестве функий расстояния между векторами использовались метрики, порождённые $L_1$  и $L_2$ нормами.
        Кроме того, для каждого из временных рядов была обучена авторегрессионная модель, на основе коэффициентов которых также произведена кластеризация.
        Так как в процессе получения данных были возможны различные положения телефона в кармане, кластеризация проводилась на 4, 12, 24, 36 и 48 кластеров.

        \begin{table}[h]
            \centering
            \begin{tabular}{c|c *{2}{|*{3}{c}}}
                \toprule
                \multirow{2}{*}{$\rho$} & \multirow{2}{*}{$N_{clust}$} & \multicolumn{3}{c|}{$Q_1$} & \multicolumn{3}{c}{$Q_2$} \\
                \cmidrule(r){3-8}
                && \textit{complete} & \textit{average} & \textit{weighted} & \textit{complete} & \textit{average} & \textit{weighted} \\
                \midrule
            \multirow{5}{*}{$L_1$}
                    &  4 & $0.42\pm 0.07$ & $0.51\pm 0.07$ & $0.55\pm 0.06$ & $0.22\pm 0.09$ & $0.31\pm 0.10$ & $0.36\pm 0.09$ \\
                    & 12 & $0.46\pm 0.09$ & $0.54\pm 0.04$ & $0.57\pm 0.04$ & $0.24\pm 0.05$ & $0.33\pm 0.05$ & $0.36\pm 0.05$ \\
                    & 24 & $0.50\pm 0.03$ & $0.57\pm 0.03$ & $0.59\pm 0.03$ & $0.28\pm 0.03$ & $0.36\pm 0.04$ & $0.38\pm 0.04$ \\
                    & 36 & $0.55\pm 0.02$ & $0.60\pm 0.02$ & $0.61\pm 0.03$ & $0.33\pm 0.03$ & $0.40\pm 0.03$ & $0.41\pm 0.05$ \\
                    & 48 & $0.58\pm 0.02$ & $0.63\pm 0.02$ & $0.64\pm 0.03$ & $0.37\pm 0.03$ & $0.43\pm 0.03$ & $0.44\pm 0.04$ \\
            \midrule
            \multirow{5}{*}{$L_2$}
                    &  4 & $0.42\pm 0.06$ & $0.47\pm 0.07$ & $0.54\pm 0.06$ & $0.22\pm 0.07$ & $0.26\pm 0.09$ & $0.35\pm 0.09$\\
                    & 12 & $0.46\pm 0.04$ & $0.53\pm 0.04$ & $0.59\pm 0.04$ & $0.25\pm 0.05$ & $0.32\pm 0.05$ & $0.39\pm 0.05$ \\
                    & 24 & $0.50\pm 0.03$ & $0.57\pm 0.03$ & $0.59\pm 0.03$ & $0.28\pm 0.03$ & $0.35\pm 0.04$ & $0.39\pm 0.03$ \\
                    & 36 & $0.54\pm 0.03$ & $0.60\pm 0.03$ & $0.62\pm 0.03$ & $0.33\pm 0.03$ & $0.40\pm 0.04$ & $0.42\pm 0.03$ \\
                    & 48 & $0.58\pm 0.02$ & $0.63\pm 0.03$ & $0.64\pm 0.03$ & $0.37\pm 0.03$ & $0.43\pm 0.04$ & $0.46\pm 0.04$ \\
            \midrule
            \multirow{5}{*}{$AR$}
                    &  4 & \multicolumn{3}{c|}{$0.52\pm 0.06$} & \multicolumn{3}{c|}{$0.32\pm 0.08$}\\
                    & 12 & \multicolumn{3}{c|}{$0.61\pm 0.05$} & \multicolumn{3}{c|}{$0.42\pm 0.06$} \\
                    & 24 & \multicolumn{3}{c|}{$0.67\pm 0.05$} & \multicolumn{3}{c|}{$0.51\pm 0.07$} \\
                    & 36 & \multicolumn{3}{c|}{$0.70\pm 0.03$} & \multicolumn{3}{c|}{$0.55\pm 0.05$} \\
                    & 48 & \multicolumn{3}{c|}{$0.73\pm 0.03$} & \multicolumn{3}{c|}{$0.59\pm 0.05$} \\
            \bottomrule
            \end{tabular}
            \caption{Кластеризация.}
        \end{table}

    В большинстве случаев лучшие результаты показал метод кластеризации $weighted$.
    При этом, методы выравнивания с $L_1$ и $L_2$ метриками показали примерно равные результаты. Простейшая регрессионная модель позволила достичь лучшего качества во всех экспериментах.
						
    На картинках \ref{img1}, \ref{img2} приводится примеры рядов, отнесенных к одному кластеру,
        выравненных относительно случайного набора рядов из данного кластера для $L_1$ и $L_2$ метрик соответственно.
    Кластеризация в данных примерах проводилась с помощью метода $weighted$.

    \begin{figure}[h!]
        \includegraphics[width=\textwidth]{images/img2.eps}
        \caption{Кластеризация с $L_1$} \label{img1}
    \end{figure}
    \begin{figure}[h!]
        \includegraphics[width=\textwidth]{images/img3.eps}
        \caption{Кластеризация с $L_2$} \label{img2}
    \end{figure}                
    % \section{Заключение}
    
    

    \bibliography{literature} 
    \bibliographystyle{unsrt}
    
    % Решение Программного Комитета:
    %\ACCEPTNOTE
    %\AMENDNOTE
    %\REJECTNOTE
\end{document}
    

    
