{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import sleep, time\n",
    "from threading import Thread\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from testing import TestFactory, ClusteredInfo\n",
    "from dtw import dtw as cur_dtw\n",
    "from dtw_wrapper import DtwWrapper\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_SIZES = [4, 12, 24, 36, 48]\n",
    "N_CLUST = 30\n",
    "EXE = \"./bin/MDTW_pairwise.exe\"\n",
    "\n",
    "def metric_Q(info):\n",
    "    Q = 0\n",
    "    norm_koeff = 0\n",
    "    for i in range(info.count): \n",
    "        for j in range(info.count):\n",
    "            if info.label[i] == info.label[j]:\n",
    "                norm_koeff += 1\n",
    "            if info.label[i] == info.label[j] and info.clusters_labels[i] == info.clusters_labels[j]:\n",
    "                Q += 1\n",
    "                \n",
    "    return Q / norm_koeff\n",
    "\n",
    "\n",
    "def metric_cluster(info):\n",
    "    Q = 0\n",
    "    for i in range(1, info.cluster_num + 1):\n",
    "        ind, counts = np.unique(info.label[np.where(info.clusters_labels == i)[0]], return_counts=True)\n",
    "        Q += counts.max() / counts.sum()\n",
    "\n",
    "    return Q / info.cluster_num\n",
    "\n",
    "def metric_cluster_vlad(info):\n",
    "    Q = 0\n",
    "    for i in range(1, info.cluster_num + 1):\n",
    "        ind, counts = np.unique(info.label[np.where(info.clusters_labels == i)[0]], return_counts=True)\n",
    "        Q += (counts.max()) ** 2 / len(np.where(info.clusters_labels == i)[0]) / counts.sum() \n",
    "\n",
    "    return Q / info.cluster_num\n",
    "\n",
    "def norm_1(x, y):\n",
    "    return np.linalg.norm(x - y, ord=1)\n",
    "def norm_2(x, y):\n",
    "    return np.linalg.norm(x - y, ord=2)\n",
    "\n",
    "def cosine(x, y):\n",
    "    return 1 - abs(np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y)))\n",
    "\n",
    "def pipeline(info, autoregression=False, show_results=True):\n",
    "    metrics = {0: [], 1: []}\n",
    "    \n",
    "    info.cluster(N_CLUST)\n",
    "    Q1 = metric_cluster(info)\n",
    "    Q2 = metric_cluster_vlad(info)\n",
    "        \n",
    "    for cluster_size in CLUSTER_SIZES:\n",
    "        info.cluster(cluster_size)\n",
    "        Q1 = metric_cluster(info)\n",
    "        Q2 = metric_cluster_vlad(info)\n",
    "        metrics[0].append(Q1)\n",
    "        metrics[1].append(Q2)\n",
    "        if show_results:\n",
    "            print(\"{0:4}: Q1:{1:.4f} | Q2:{2:.4f}\".format(cluster_size, Q1, Q2))\n",
    "    \n",
    "    if not show_results:\n",
    "        return metrics[0], metrics[1]\n",
    "\n",
    "    index = info.stats.head(10).index.values\n",
    "    classifier_stat = {}\n",
    "    for i in info.stats.index:\n",
    "        classifier_stat[i] = pd.Series(info.label[np.where(info.clusters_labels == i)[0]]).value_counts()\n",
    "\n",
    "    display(pd.DataFrame(classifier_stat).fillna(0).iloc[:, :30])\n",
    "    \n",
    "    for i in index[:6]:\n",
    "        info.clusters_compare_table(label=i, z_normalize=True)\n",
    "    plt.show()\n",
    "    \n",
    "    display(Markdown(\"#### До выравнивания\"))\n",
    "    for i in index[:6]:\n",
    "        info.comparing_at_one(i, num_series=10, z_normalize=True)\n",
    "    plt.show()\n",
    "    \n",
    "    if not autoregression:\n",
    "        display(Markdown(\"#### С выравниванием\"))\n",
    "        for i in index[:6]:\n",
    "            info.allignment_to_random(i, num_series=10, z_normalize=True)\n",
    "        plt.show()\n",
    "        \n",
    "    return metrics[0], metrics[1]\n",
    "        \n",
    "def repeat_test(args, kwargs, n_repeat, sample_size, autoregression=False, external=True, norm=1):\n",
    "    metrics = []\n",
    "    for i in range(n_repeat):\n",
    "        print(i)\n",
    "        tests = TestFactory(random_state=i)\n",
    "        x = tests.set_sample(sample_size)\n",
    "        if external:\n",
    "            path = \"../data/clustering/to_compute/akselerometr_{0}.csv\".format(i)\n",
    "            np.savetxt(path, np.concatenate(x[0]))\n",
    "            command = [EXE, path, \"3\", str(norm), \"200\", \"20\"]\n",
    "            try:\n",
    "                stdout = subprocess.check_output(command).decode()\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(e.output)\n",
    "\n",
    "            kwargs[\"external\"] = True\n",
    "            kwargs[\"external_distances_path\"] =  \"../data/clustering/to_compute/akselerometr_{0}.csv_results\".format(i)\n",
    "        info = tests.ar_clustering() if autoregression else tests.test_dtw(*args, **kwargs)\n",
    "\n",
    "        metrics.append(pipeline(info, autoregression, show_results=False))\n",
    "\n",
    "    print(\"\\n---- Metrics ----\\n\")\n",
    "    print(\"  \".join([\"{0:0.3f}+-{1:0.3f}\".format(s, m) for s, m in zip(\n",
    "        np.mean(np.array(metrics)[:, 0, :], 0),\n",
    "        np.std(np.array(metrics)[:, 0, :], 0))]))\n",
    "    print(\"  \".join([\"{0:0.3f}+-{1:0.3f}\".format(s, m) for s, m in zip(\n",
    "            np.mean(np.array(metrics)[:, 1, :], 0),\n",
    "            np.std(np.array(metrics)[:, 1, :], 0))]))\n",
    "\n",
    "    print(\"{0:0.4f} +- {1:0.4f}\".format(np.mean(np.array(metrics)[:, 0, :]), np.std(np.array(metrics)[:, 0, :])))\n",
    "    print(\"{0:0.4f} +- {1:0.4f}\".format(np.mean(np.array(metrics)[:, 1, :]), np.std(np.array(metrics)[:, 1, :])))\n",
    "\n",
    "    return metrics, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTW\n",
    "Стоит играться с функциями расстояния между кластерами.  \n",
    "Сейчас стоит `complete`: $$d(X, Y) = max(dist(x, y))$$\n",
    "\n",
    "Более менее работает с `weighted` и `average`.  \n",
    "[Подробнее](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage)\n",
    "\n",
    "Практически во всех способах, остается первый кластер, размер которого самый большой. В нем, зачастую, все перемемашно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_REPEATS = 10\n",
    "SAMPLE_SIZE = 800\n",
    "tests = TestFactory(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 1\n",
    "f_norm = norm_1\n",
    "for cluster_dist in [\"complete\", \"weighted\", \"average\"]:\n",
    "    display(Markdown(\"## {}\".format(cluster_dist)))\n",
    "    metrics, info = repeat_test([cur_dtw, f_norm],\n",
    "                          {\"dtw_args\": {\"z_normalize\": False, \"l\": 0.2}, \"cluster_dist\": cluster_dist},\n",
    "                         N_REPEATS, SAMPLE_SIZE, norm=norm)\n",
    "\n",
    "    pipeline(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 1\n",
    "f_norm = norm_1\n",
    "for cluster_dist in [\"complete\", \"weighted\", \"average\"]:\n",
    "    display(Markdown(\"## {}\".format(cluster_dist)))\n",
    "    metrics, info = repeat_test([cur_dtw, f_norm],\n",
    "                          {\"dtw_args\": {\"z_normalize\": False, \"l\": 0.2}, \"cluster_dist\": cluster_dist},\n",
    "                         N_REPEATS, SAMPLE_SIZE, norm=norm)\n",
    "\n",
    "    pipeline(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 3\n",
    "f_norm = cosine\n",
    "for cluster_dist in [\"complete\", \"weighted\", \"average\"]:\n",
    "    display(Markdown(\"## {}\".format(cluster_dist)))\n",
    "    metrics, info = repeat_test([cur_dtw, f_norm],\n",
    "                          {\"dtw_args\": {\"z_normalize\": False, \"l\": 0.2}, \"cluster_dist\": cluster_dist},\n",
    "                         N_REPEATS, SAMPLE_SIZE, norm=norm)\n",
    "\n",
    "    pipeline(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_REPEATS = 3\n",
    "SAMPLE_SIZE = 100\n",
    "tests = TestFactory(random_state=42)\n",
    "\n",
    "CLUSTER_SIZES = [4, 12, 24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 1\n",
    "f_norm = norm_1\n",
    "for cluster_dist in [\"complete\", \"weighted\", \"average\"]:\n",
    "    display(Markdown(\"## {}\".format(cluster_dist)))\n",
    "    metrics, info = repeat_test([cur_dtw, f_norm],\n",
    "                          {\"dtw_args\": {\"z_normalize\": False, \"l\": 0.2}, \"cluster_dist\": cluster_dist},\n",
    "                         N_REPEATS, SAMPLE_SIZE, norm=norm, external=False)\n",
    "\n",
    "    pipeline(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 1\n",
    "f_norm = norm_1\n",
    "for cluster_dist in [\"complete\", \"weighted\", \"average\"]:\n",
    "    display(Markdown(\"## {}\".format(cluster_dist)))\n",
    "    metrics, info = repeat_test([cur_dtw, f_norm],\n",
    "                          {\"dtw_args\": {\"z_normalize\": False, \"l\": 0.2}, \"cluster_dist\": cluster_dist},\n",
    "                         N_REPEATS, SAMPLE_SIZE, norm=norm, external=False)\n",
    "\n",
    "    pipeline(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 3\n",
    "f_norm = cosine\n",
    "for cluster_dist in [\"complete\", \"weighted\", \"average\"]:\n",
    "    display(Markdown(\"## {}\".format(cluster_dist)))\n",
    "    metrics, info = repeat_test([cur_dtw, f_norm],\n",
    "                          {\"dtw_args\": {\"z_normalize\": False, \"l\": 0.2}, \"cluster_dist\": cluster_dist},\n",
    "                         N_REPEATS, SAMPLE_SIZE, norm=norm, external=False)\n",
    "\n",
    "    pipeline(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = repeat_test(None, None, N_REPEATS, SAMPLE_SIZE, True)\n",
    "tests = TestFactory(random_state=1)\n",
    "_ = tests.set_sample(600)\n",
    "info = tests.ar_clustering()\n",
    "pipeline(info, autoregression=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtw",
   "language": "python",
   "name": "dtw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
