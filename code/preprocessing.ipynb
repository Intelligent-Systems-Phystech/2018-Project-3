{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import sleep, time\n",
    "from threading import Thread\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from data_processing import DataIterator\n",
    "from testing import TestFactory, ClusteredInfo\n",
    "from dtw import dtw as cur_dtw\n",
    "from dtw_wrapper import DtwWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_1(x, y):\n",
    "    return np.linalg.norm(x - y, ord=1)\n",
    "def norm_2(x, y):\n",
    "    return np.linalg.norm(x - y, ord=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewriting data in our format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"../data/preprocessed_large.csv\", header=None)\n",
    "\n",
    "# indexes = pd.Index(range(0, 200))\n",
    "# data_preprocessed = pd.DataFrame(columns=[\"obj\", \"ch\", \"label\", *indexes])\n",
    "\n",
    "# l = []\n",
    "# for j in data.index:\n",
    "#     df = pd.DataFrame({\"obj\": [j for i in range(3)], \n",
    "#                   \"label\": [data.loc[j, 0] for i in range(3)]},\n",
    "#                  columns=[\"obj\", \"label\", *indexes])\n",
    "#     df.index.name = \"ch\"\n",
    "#     df.loc[0, indexes] = data.loc[j, 1:200].values\n",
    "#     df.loc[1, indexes] = data.loc[j, 201:400].values\n",
    "#     df.loc[2, indexes] = data.loc[j, 401:600].values \n",
    "#     df.reset_index(inplace=True)\n",
    "#     data_preprocessed = data_preprocessed.append(df, sort=False)\n",
    "    \n",
    "# data_preprocessed.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/preprocessed_3ch_50point_overlap0.csv\", index_col=0)\n",
    "it = DataIterator(data, 50, random_state=42)\n",
    "tests = TestFactory(it=it)\n",
    "x = tests.set_sample(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = DtwWrapper(tests.X, hash(tests.infos), cur_dtw, norm_1, dtw_args={\"z_normalize\": True, \"l\": 0.2})\n",
    "wrap.fill_distances(n_threads=8)\n",
    "\n",
    "wrap = DtwWrapper(tests.X, hash(tests.infos), cur_dtw, norm_2, dtw_args={\"z_normalize\": True, \"l\": 0.2})\n",
    "wrap.fill_distances(n_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.genfromtxt(\"../data/distances/dtwnorm_1z_normalizeTruel0.2-43544539162478229291.csv\")\n",
    "(tmp < 0).sum() / (tmp != -1000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = tests.test_dtw(cur_dtw, norm_2, \n",
    "                      dtw_args={\"z_normalize\": True, \"l\": 0.2}, cluster_dist=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.cluster(50)\n",
    "info.stats\n",
    "index = info.stats.head(10).index.values\n",
    "classifier_stat = {}\n",
    "for i in info.stats.index:\n",
    "    classifier_stat[i] = pd.Series(info.label[np.where(info.clusters_labels == i)[0]]).value_counts()\n",
    "    \n",
    "pd.DataFrame(classifier_stat).fillna(0).iloc[:, :30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = tests.test_dtw(cur_dtw, norm_1, \n",
    "                      dtw_args={\"z_normalize\": True, \"l\": 0.2},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.cluster(24)\n",
    "info.stats\n",
    "index = info.stats.head(10).index.values\n",
    "classifier_stat = {}\n",
    "for i in info.stats.index:\n",
    "    classifier_stat[i] = pd.Series(info.label[np.where(info.clusters_labels == i)[0]]).value_counts()\n",
    "    \n",
    "pd.DataFrame(classifier_stat).fillna(0).iloc[:, :30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewriting accelerometer dataset 2\n",
    "[Link](https://github.com/mmalekzadeh/motion-sense/blob/master/data/B_Accelerometer_data.zip \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 200\n",
    "labels = np.unique([x[:3] for x in os.listdir(\"../data/B_Accelerometer_data/\")])\n",
    "dirs = os.listdir(\"../data/B_Accelerometer_data/\")\n",
    "d = dict((label, i) for (i, label) in enumerate(labels))\n",
    "counter = 0\n",
    "\n",
    "indexes = pd.Index(range(SAMPLE_SIZE))\n",
    "data_preprocessed = pd.DataFrame(columns=[\"obj\", \"ch\", \"label\", *indexes])\n",
    "\n",
    "for dir in dirs:\n",
    "    for f in os.listdir(\"../data/B_Accelerometer_data/{}\".format(dir)):\n",
    "        data = pd.read_csv(\"../data/B_Accelerometer_data/{}/{}\".format(dir, f), index_col=0)\n",
    "        data = data.T.rename({\"x\": 0, \"y\": 1, \"z\": 2}).reset_index().rename(columns={\"index\": \"ch\"})\n",
    "\n",
    "        for start in range(0, data.shape[-1] - SAMPLE_SIZE, SAMPLE_SIZE):\n",
    "            df = pd.DataFrame(\n",
    "                {\n",
    "                    \"obj\": [counter for i in range(3)], \n",
    "                    \"label\": [d[dir[:3]] for i in range(3)]},\n",
    "                    columns=[\"obj\", \"label\", *indexes])\n",
    "            \n",
    "            df.index.name = \"ch\"\n",
    "            df.loc[:, indexes] = data.iloc[:, start:start + size].values\n",
    "            df.reset_index(inplace=True)\n",
    "            data_preprocessed = data_preprocessed.append(df, sort=False)\n",
    "            counter += 1\n",
    "\n",
    "data_preprocessed.reset_index(drop=True, inplace=True)\n",
    "data_preprocessed.to_csv(\"../data/clustering/accelerometer2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtw",
   "language": "python",
   "name": "dtw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
